{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find repo root even if notebook is inside /notebooks\n",
    "ROOT = Path.cwd()\n",
    "if ROOT.name == \"notebooks\":\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "DATA_DIR = ROOT / \"data\"\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_csv_ranges(file_path,delim=\",\"):\n",
    "    \"\"\"\n",
    "    Analyze a CSV file to separate columns and find ranges for all columns.\n",
    "    For numeric columns: calculates min, max, range\n",
    "    For text columns: shows unique count and sample values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path,delimiter=delim)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return\n",
    "    \n",
    "    print(df.describe())\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Total rows: {len(df)}\")\n",
    "    print(f\"Total columns: {len(df.columns)}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "\n",
    "    for i, column in enumerate(df.columns):\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Column {i}: {column}\")\n",
    "        print(\"-\" * 80)\n",
    "        col_data = df[column]\n",
    "        first_data = 0\n",
    "        for n in range(len(col_data)):\n",
    "            if pd.isna(col_data[n]):\n",
    "                first_data = n\n",
    "            else: break\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(col_data): # Check if data is numeric\n",
    "            clean_data = col_data.dropna()\n",
    "            if len(clean_data)>0:\n",
    "                min_val = clean_data.min()\n",
    "                max_val = clean_data.max()\n",
    "                print(f\"Minimim Value: {min_val}\")\n",
    "                print(f\"Maximum Value: {max_val}\")\n",
    "                print(f\"Mean: {clean_data.mean():.2f}\")\n",
    "            else:\n",
    "                print(\"All NaN or empty\")\n",
    "        else: \n",
    "            print(\"Type: Text/Categorcal\")\n",
    "\n",
    "        print(f\"Preview of Column:\")\n",
    "        print(col_data[:3])\n",
    "        print(col_data[-3:])\n",
    "        print(f\"Total values: {len(col_data)}\")\n",
    "        print(f\"Unique values: {col_data.nunique()}\")\n",
    "        print(f\"Missing values: {col_data.isna().sum()}\")\n",
    "        print(f'First value at: row number: {first_data}, on the {df[\"ts\"][first_data]}')\n",
    "        print(f\"Fraction of No Readings {col_data.isna().sum()/len(col_data)} \")\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = analyze_csv_ranges(DATA_DIR / 'combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 12), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='ts').corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### **Data Frame with Positive Generation only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with no zeros, i.e. positive or zero generation only\n",
    "\n",
    "df_positive_generation =  analyze_csv_ranges(DATA_DIR / 'combined_data_positive_gen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = df_positive_generation.hist(figsize=(12, 12), bins=20)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    title = ax.get_title()\n",
    "    \n",
    "    # Wrap title after certain character width\n",
    "    wrapped_title = \"\\n\".join(textwrap.wrap(title, width=20))\n",
    "    \n",
    "    ax.set_title(wrapped_title, fontsize=11)\n",
    "    #ax.set_xlabel(\"Power [kW]\", fontsize=10)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=10)\n",
    "    \n",
    "    # Improve tick readability\n",
    "    ax.tick_params(axis='both', labelsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_generation.drop(columns='ts').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_csv_ranges(DATA_DIR / f'SyslabWind_15min.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### I would chose the Aircon instead of Gaia, since Aircon has 10% no readings and Gaia has 25% no readings.\n",
    "larger breaks: \n",
    "- July 30 - Aug 4\n",
    "- Aug 8-22\n",
    "- Oct 16-17\n",
    "- and every once in a while theres a hole for a few hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_csv_ranges(DATA_DIR/'SyslabWeather_15min.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### **SOLETE Data**\n",
    "\n",
    "'The dataset includes 15 months of measurements from the 1st June 2018 to 1st September 2019 covering: Timestamp, air temperature, relative humidity, pressure, wind speed, wind direction, global horizontal irradiance, plane of array irradiance, and active power recorded from an 11 kW Gaia wind turbine and a 10 kW PV inverter.'\n",
    "\n",
    "[1] SOLETE, a 15-month long holistic dataset including: Meteorology, co-located wind and solar PV power from Denmark with various resolutions (https://www.sciencedirect.com/science/article/pii/S2352340922002578#bib0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSOLETE = analyze_csv_ranges(DATA_DIR / 'SOLETE_1sec_15min.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSOLETE.drop(columns='ts').corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = dfSOLETE.hist(figsize=(12, 12), bins=20)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    title = ax.get_title()\n",
    "    \n",
    "    # Wrap title after certain character width\n",
    "    wrapped_title = \"\\n\".join(textwrap.wrap(title, width=20))\n",
    "    \n",
    "    ax.set_title(wrapped_title, fontsize=11)\n",
    "    #ax.set_xlabel(\"Power [kW]\", fontsize=10)\n",
    "    ax.set_ylabel(\"Frequency\", fontsize=10)\n",
    "    \n",
    "    # Improve tick readability\n",
    "    ax.tick_params(axis='both', labelsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "- What columns are mostly 0 or empty?\n",
    "\n",
    "No empty columns or rows. \n",
    "\n",
    "Power Gaia, Azimuth and Elevation have all 0 quantiles (25%, 50%, 75%)\n",
    "\n",
    "- If there any, where are the big gaps in data?\n",
    "\n",
    "There's no gaps in the data, only several occassions when the recorded data is 0. \n",
    "\n",
    "- How does this Gaia compare to the bigger dataframe's Gaia?\n",
    "\n",
    "The data on the Gaia turbine first downloaded in SyslabWind.csv has 25% of gaps while SOLETE's has no gaps\n",
    "\n",
    "Still, in SOLETE, the median is 0.0000 and the mean is 0.0002 with a max value of 10.552675555555554, which is close to the rated power (11 kW). Thus, it's a single or few outliers that show relevant power outputs, otherwise the data is irrelevant at 0 kW. It's correlation with wind speed is also corcerning at a mere 0.038058. :(((\n",
    "\n",
    "- What does the solar production look like?\n",
    "\n",
    "It has a strong correlation with the two irradiation types recorded: GHI (0.921497) and POA (0.998715)\n",
    "\n",
    "The documentation on SOLETE states that the inverter has a power capacity of 10 kW, yet the following are the recorded values for the PV's output: \n",
    "\n",
    "median: 0.072028; mean: 1.024447; 75% quantile: 1.313590; max: 7.098779\n",
    "\n",
    "It performs better than the PV unit in B715, yet it still seems to underperform :(\n",
    "\n",
    "- Is there a correlation between the solar resource and the production?\n",
    "\n",
    "Strong correlation between the two types of solar irradiation (GHI and POA Irr) and the PV Power Production ('Power Solar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### **DTU Buildings Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_csv_ranges(DATA_DIR/ 'DTU_B325_B329_B329A_15min.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Comments of building data:\n",
    "- When are some of the most evident gaps?\n",
    "\n",
    "We have data for the following periods: \n",
    "\n",
    "2021-02-28 23:00:00 until 2021-03-27 23:45:00 for all data sets\n",
    "\n",
    "2021-03-28 00:15:00 until for 2021-03-28 00:45:00 for cols 6, 7, and 11\n",
    "\n",
    "2021-03-28 01:00:00 until 2021-03-30 21:45:00 for all cols\n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2021-04-05 22:00:00 until 2021-04-28 21:15:00 for all cols\n",
    "\n",
    "2021-04-28 21:30:00 until 2021-04-28 21:45:00 for cols 8 and 24\n",
    "\n",
    "2021-04-28 22:00:00 until 2021-04-30 08:45:00 for most cols\n",
    "\n",
    "2021-04-30 22:00:00 until 2021-05-05 21:45:00 for all cols\n",
    "\n",
    "**BIGGER GAP**\n",
    "\n",
    "2021-10-19 22:00:00 until 2021-10-20 21:45:00 for all cols\n",
    "\n",
    "2021-10-21 22:00:00 until 2021-10-25 21:45:00 for all cols\n",
    "\n",
    "2021-10-25 22:00:00 until 2021-10-26 21:45:00 only for col 2\n",
    "\n",
    "2021-10-26 22:00:00 until 2021-10-30 22:45:00 for all cols\n",
    "\n",
    "2021-10-31 01:00:00 until 2021-11-03 17:30:00 for most cols\n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2021-11-03 19:30:00 until 2021-11-04 22:45:00 for most cols\n",
    "\n",
    "2021-11-04 23:00:00 until 2021-11-05 22:45:00 only for col 2\n",
    "\n",
    "2021-11-05 23:00:00 until 2021-11-06 22:45:00 for all cols\n",
    "\n",
    "2021-11-06 23:00:00 until 2021-11-07 21:45:00 only for col 2\n",
    "\n",
    "2021-11-07 23:00:00 until 2021-11-11 20:15:00 for most cols \n",
    "\n",
    "2021-11-11 23:00:00 until 2021-11-12 17:30:00 for most cols \n",
    "\n",
    "2021-11-12 23:00:00 until 2021-11-13 17:15:00 for most cols \n",
    "\n",
    "2021-11-13 23:00:00 until 2021-11-14 15:00:00 for most cols\n",
    "\n",
    "2021-11-14 23:00:00 until 2021-11-15 12:30:00 for most cols\n",
    "\n",
    "2021-11-16 13:30:00 until 2021-11-16 17:00:00 only for col 23\n",
    "\n",
    "2021-11-16 19:15:00 until 2021-11-18 05:15:00 for most cols \n",
    "\n",
    "2021-11-18 13:15:00 until 2021-11-18 21:00:00 for most cols \n",
    "\n",
    "2021-11-19 05:30:00 until 2022-01-12 01:45:00 for most cols\n",
    "\n",
    "**BIGGER GAP**\n",
    "\n",
    "2022-01-12 19:15:00 until 2022-01-12 20:45:00 only for col 17\n",
    "\n",
    "2022-01-12 21:00:00 until 2022-02-03 13:45:00 for most cols \n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-02-03 18:45:00 until  for most cols \n",
    "\n",
    "=> one hour gap 2022-03-26 00:00:00-2022-03-27 01:00:00\n",
    "\n",
    "2022-03-27 01:00:00 until 2022-04-30 21:45:00 for most cols \n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-04-30 22:00:00 until 2022-05-01 21:45:00 only for col 2\n",
    "\n",
    "2022-05-01 22:00:00 until 2022-05-18 17:15:00 for most cols \n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-05-18 22:00:00 until 2022-06-01 21:45:00 for most cols\n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-06-02 22:00:00 until 2022-06-20 14:15:00 for most cols \n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-06-24 03:30:00 until 2022-07-05 21:45:00 for most cols \n",
    "\n",
    "**SMALL GAP**\n",
    "\n",
    "2022-07-05 22:00:00 until 2022-07-06 21:45:00 only for col 2\n",
    "\n",
    "- How is this data relevant?\n",
    "\n",
    "Data on buildings B415, B325, B329, B346, B349\n",
    "\n",
    "The total consumption of B325 is registered as well as that of its mixing plant total energy consumption and the consumption of specific rooms (R: 329, 961, 901B (two meters), 915, 951)\n",
    "\n",
    "- Did you look into the naming legend linked in Energy Data Hub?\n",
    "\n",
    "The link where the naming of the sensors is supposed to be detailed does not work. I also can't find anything with BMS on the current DTU website. Maybe we can request the data?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsc-proj-venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
